# -*- coding: utf-8 -*-
"""ML_Final project_Chuanyu Liu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jH3dWjqh24FpDSyEQ1d2ynV3I2aEvhif
"""

!pip install schnetpack

import os
import schnetpack as spk

data2Dsave = './data2Dsave'
if not os.path.exists('data2Dsave'):
    os.makedirs(data2Dsave)
data3Dsave = './data3Dsave'
if not os.path.exists('data3Dsave'):
    os.makedirs(data3Dsave)

import schnetpack.train as trn

from google.colab import files
uploaded = files.upload()

from schnetpack.data import AtomsLoader, AtomsData

data2D = AtomsData(dbpath='2d_qm9.db', available_properties = ['u0','bandgap'])
data3D = AtomsData(dbpath='3d_qm9.db',available_properties = ['u0','bandgap'])

"""**Building the Model with 2D_qm9**"""

train_2D , val_2D, test_2D = spk.train_test_split(
        data=data2D,
        num_train=1000,
        num_val=500,
    )

train_loader_2D = spk.AtomsLoader(train_2D, batch_size=100, shuffle=True)
val_loader_2D = spk.AtomsLoader(val_2D, batch_size=100)

means_2D, stddevs_2D = train_loader_2D.get_statistics(
    'u0'
)
print('Mean atomization energy / atom:', means_2D['u0'])
print('Std. dev. atomization energy / atom:', stddevs_2D['u0'])



"""**Building the model(2D_qm9)**"""

schnet_2D = spk.representation.SchNet(
    n_atom_basis=30, n_filters=30, n_gaussians=20, n_interactions=5,
    cutoff=4., cutoff_network=spk.nn.cutoff.CosineCutoff
)

output_U0_2D = spk.atomistic.Atomwise(n_in=30, property='u0',
                                   mean=means_2D['u0'], stddev=stddevs_2D['u0'])
model_2D = spk.AtomisticModel(representation=schnet_2D, output_modules=output_U0_2D)

"""**Training the model(2D_qm9)**"""

from torch.optim import Adam

# loss function
def mse_loss(batch, result):
    diff = batch['u0']-result['u0']
    err_sq = torch.mean(diff ** 2)
    return err_sq

# build optimizer
optimizer_2D = Adam(model_2D.parameters(), lr=1e-2)

# Commented out IPython magic to ensure Python compatibility.
# %rm -r ./data2Dsave/checkpoints
# %rm -r ./data2Dsave/log.csv
# %rm -r ./data2Dsave/best_model

loss_2D = trn.build_mse_loss(['u0'])

metrics_2D = [spk.metrics.MeanAbsoluteError('u0')]
hooks_2D = [
    trn.CSVHook(log_path=data2Dsave, metrics=metrics_2D),
    trn.ReduceLROnPlateauHook(
        optimizer_2D,
        patience=5, factor=0.8, min_lr=1e-6,
        stop_after_min=True
    )
]

trainer_2D = trn.Trainer(
    model_path=data2Dsave,
    model=model_2D,
    hooks=hooks_2D,
    loss_fn=loss_2D,
    optimizer=optimizer_2D,
    train_loader=train_loader_2D,
    validation_loader=val_loader_2D,
)

device = "cuda" # change to 'cpu' if gpu is not available
n_epochs = 200 # takes about 10 min on a notebook GPU. reduces for playing around
trainer_2D.train(device=device, n_epochs=n_epochs)

"""**Performance(2D)**"""

import numpy as np
import matplotlib.pyplot as plt
from ase.units import kcal, mol

results_2D = np.loadtxt(os.path.join(data2Dsave, 'log.csv'), skiprows=1, delimiter=',')

time_2D = results_2D[:,0]-results_2D[0,0]
learning_rate_2D = results_2D[:,1]
train_loss_2D = results_2D[:,2]
val_loss_2D = results_2D[:,3]
val_mae_2D = results_2D[:,4]

print('Final validation MAE:', np.round(val_mae_2D[-1], 2), 'eV =',
      np.round(val_mae_2D[-1] / (kcal/mol), 2), 'kcal/mol')

plt.figure(figsize=(14,5))
plt.subplot(1,2,1)
plt.plot(time_2D, val_loss_2D, label='Validation')
plt.plot(time_2D, train_loss_2D, label='Train')
plt.yscale('log')
plt.ylabel('Loss [eV]')
plt.xlabel('Time [s]')
plt.legend()
plt.subplot(1,2,2)
plt.plot(time_2D, val_mae_2D)
plt.ylabel('mean abs. error [eV]')
plt.xlabel('Time [s]')
plt.show()

import torch
best_model_2D = torch.load(os.path.join(data2Dsave, 'best_model'))

test_loader_2D = spk.AtomsLoader(test_2D, batch_size=100)

err_2D = 0
print(len(test_loader_2D))
for count, batch in enumerate(test_loader_2D):
    # move batch to GPU, if necessary
    batch = {k: v.to(device) for k, v in batch.items()}

    # apply model
    pred = best_model_2D(batch)

    # calculate absolute error
    tmp = torch.sum(torch.abs(pred['u0']-batch['u0']))
    tmp = tmp.detach().cpu().numpy() # detach from graph & convert to numpy
    err_2D += tmp

    # log progress
    percent = '{:3.2f}'.format(count/len(test_loader_2D)*100)
    print('Progress:', percent+'%'+' '*(5-len(percent)), end="\r")

err_2D /= len(test_2D)
print('Test MAE', np.round(err_2D, 2), 'eV =',
      np.round(err_2D / (kcal/mol), 2), 'kcal/mol')

"""**Building the Model with 3D_qm9**"""

train_3D , val_3D, test_3D = spk.train_test_split(
        data=data3D,
        num_train=1000,
        num_val=500,
    )

train_loader_3D = spk.AtomsLoader(train_3D, batch_size=100, shuffle=True)
val_loader_3D = spk.AtomsLoader(val_3D, batch_size=100)

means_3D, stddevs_3D = train_loader_3D.get_statistics(
    'u0'
)
print('Mean atomization energy / atom:', means_3D['u0'])
print('Std. dev. atomization energy / atom:', stddevs_3D['u0'])

"""**Building the model(3D_qm9)**"""

schnet_3D = spk.representation.SchNet(
    n_atom_basis=30, n_filters=30, n_gaussians=20, n_interactions=5,
    cutoff=4., cutoff_network=spk.nn.cutoff.CosineCutoff
)

output_U0_3D = spk.atomistic.Atomwise(n_in=30, property='u0',
                                   mean=means_3D['u0'], stddev=stddevs_3D['u0'])
model_3D = spk.AtomisticModel(representation=schnet_3D, output_modules=output_U0_3D)

"""**Training the model(3D_qm9)**"""

from torch.optim import Adam

# loss function
def mse_loss(batch, result):
    diff = batch['u0']-result['u0']
    err_sq = torch.mean(diff ** 2)
    return err_sq

# build optimizer
optimizer_3D = Adam(model_3D.parameters(), lr=1e-2)

# Commented out IPython magic to ensure Python compatibility.
# %rm -r ./data3Dsave/checkpoints
# %rm -r ./data3Dsave/log.csv
# %rm -r ./data3Dsave/best_model


loss_3D = trn.build_mse_loss(['u0'])

metrics_3D = [spk.metrics.MeanAbsoluteError('u0')]
hooks_3D = [
    trn.CSVHook(log_path=data3Dsave, metrics=metrics_3D),
    trn.ReduceLROnPlateauHook(
        optimizer_3D,
        patience=5, factor=0.8, min_lr=1e-6,
        stop_after_min=True
    )
]

trainer_3D = trn.Trainer(
    model_path=data3Dsave,
    model=model_3D,
    hooks=hooks_3D,
    loss_fn=loss_3D,
    optimizer=optimizer_3D,
    train_loader=train_loader_3D,
    validation_loader=val_loader_3D,
)

device = "cuda" # change to 'cpu' if gpu is not available
n_epochs = 200 # takes about 10 min on a notebook GPU. reduces for playing around
trainer_3D.train(device=device, n_epochs=n_epochs)

"""**Performance(3D)**"""

import numpy as np
import matplotlib.pyplot as plt
from ase.units import kcal, mol

results_3D = np.loadtxt(os.path.join(data3Dsave, 'log.csv'), skiprows=1, delimiter=',')

time_3D = results_3D[:,0]-results_3D[0,0]
learning_rate_3D = results_3D[:,1]
train_loss_3D = results_3D[:,2]
val_loss_3D = results_3D[:,3]
val_mae_3D = results_3D[:,4]

print('Final validation MAE:', np.round(val_mae_3D[-1], 2), 'eV =',
      np.round(val_mae_3D[-1] / (kcal/mol), 2), 'kcal/mol')

plt.figure(figsize=(14,5))
plt.subplot(1,2,1)
plt.plot(time_3D, val_loss_3D, label='Validation')
plt.plot(time_3D, train_loss_3D, label='Train')
plt.yscale('log')
plt.ylabel('Loss [eV]')
plt.xlabel('Time [s]')
plt.legend()
plt.subplot(1,2,2)
plt.plot(time_3D, val_mae_3D)
plt.ylabel('mean abs. error [eV]')
plt.xlabel('Time [s]')
plt.show()

import torch
best_model_3D = torch.load(os.path.join(data3Dsave, 'best_model'))

test_loader_3D = spk.AtomsLoader(test_3D, batch_size=100)

err_3D = 0
print(len(test_loader_3D))
for count, batch in enumerate(test_loader_3D):
    # move batch to GPU, if necessary
    batch = {k: v.to(device) for k, v in batch.items()}

    # apply model
    pred = best_model_3D(batch)

    # calculate absolute error
    tmp = torch.sum(torch.abs(pred['u0']-batch['u0']))
    tmp = tmp.detach().cpu().numpy() # detach from graph & convert to numpy
    err_3D += tmp

    # log progress
    percent = '{:3.2f}'.format(count/len(test_loader_3D)*100)
    print('Progress:', percent+'%'+' '*(5-len(percent)), end="\r")

err_3D /= len(test_3D)
print('Test MAE', np.round(err_3D, 2), 'eV =',
      np.round(err_3D / (kcal/mol), 2), 'kcal/mol')